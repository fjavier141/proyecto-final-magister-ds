{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fjavier141/proyecto-final-magister-ds/blob/main/exploracion_inicial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njl22tiPGmzF",
    "outputId": "99e9b405-abeb-44d7-f1fd-9f8b3845b22f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conectado a: PostgreSQL 15.13 (Debian 15.13-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# =========================================\n",
    "# 1) Conexión y extracción\n",
    "# =========================================\n",
    "\n",
    "ROOT = Path().resolve().parent\n",
    "OUT_DIR = Path(\"./data/output\")\n",
    "PLOTS_DIR = OUT_DIR / \"plots\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "load_dotenv(dotenv_path=ROOT / \".env\")\n",
    "\n",
    "# Parámetros de conexión (ajusta a tu entorno)\n",
    "USER = os.getenv(\"POSTGRES_USER\")\n",
    "PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "HOST = os.getenv(\"POSTGRES_HOST\")\n",
    "PORT = os.getenv(\"POSTGRES_PORT\", \"5432\")\n",
    "DB = os.getenv(\"POSTGRES_DB\")\n",
    "\n",
    "# Crea el motor SQLAlchemy\n",
    "engine = create_engine(f\"postgresql+psycopg2://{USER}:{PASSWORD}@{HOST}:{PORT}/{DB}\")\n",
    "\n",
    "# Test de conexión\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        version = conn.execute(text(\"SELECT version();\"))\n",
    "        print(\"Conectado a:\", list(version)[0][0])\n",
    "except Exception as e:\n",
    "    print(\"Error al conectar:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracción data dimensional\n",
    "with engine.connect() as conn:\n",
    "    clientes = pd.read_sql(text(\"SELECT id_cliente, id_barrio, id_comuna, segmento, canal, descr_flag_patente FROM stg.base_clientes;\"), conn)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    barrios = pd.read_sql(text(\"SELECT id_barrio, indice_gse, n_habitantes, n_ptos_interes, superficie_km2, densidad_hab FROM stg.info_distritos;\"), conn)    \n",
    "\n",
    "with engine.connect() as conn:\n",
    "    macro_vars = pd.read_sql(text(\"SELECT id_periodo, uf, dolar, ipc, imacec, tpm, tasa_desempleo FROM stg.datos_macro;\"), conn) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracción venta cervezas\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    ventas_cervezas = pd.read_sql(text(\"SELECT id_categoria, id_cliente, id_periodo, tipo_mix, id_sku_venta, liq_um FROM stg.venta_historica WHERE id_categoria=1;\"), conn)\n",
    "\n",
    "#Extracción venta analcohólicos\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    ventas_analcoholicos = pd.read_sql(text(\"SELECT id_categoria, id_cliente, id_periodo, tipo_mix, id_sku_venta, liq_um FROM stg.venta_historica WHERE id_categoria=3;\"), conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id_categoria  id_cliente  id_periodo tipo_mix  id_sku_venta   liq_um\n",
      "0             1      719703      201811   MASIVO        450607  0.75600\n",
      "1             1      719703      201811   MASIVO        450640  0.11760\n",
      "2             1      719703      201811   MASIVO        450676  0.41748\n",
      "3             1      719703      201811  PREMIUM          7485  0.11088\n",
      "4             1      719703      201811  PREMIUM          7493  0.27720\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28327324 entries, 0 to 28327323\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   id_categoria  int64  \n",
      " 1   id_cliente    int64  \n",
      " 2   id_periodo    int64  \n",
      " 3   tipo_mix      object \n",
      " 4   id_sku_venta  int64  \n",
      " 5   liq_um        float64\n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 1.3+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Revisión general del dataset\n",
    "\n",
    "excel_path = OUT_DIR / \"eda_descriptivos.xlsx\"\n",
    "writer = pd.ExcelWriter(excel_path, engine=\"xlsxwriter\")\n",
    "\n",
    "def revision_gral_dataset(dfx, dataset_name=None, writer=None):\n",
    "    df = dfx.copy()\n",
    "\n",
    "    print(\"Dimensiones:\", df.shape)\n",
    "    print(\"Tipos de variables:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    print(\"Diccionario de datos:\")\n",
    "    for col in df.columns:\n",
    "        nunique = df[col].nunique()\n",
    "        null_pct = df[col].isna().mean() * 100\n",
    "        print(f\" - {col}: tipo={df[col].dtype}, únicos={nunique}, nulos={null_pct:.2f}%\")\n",
    "\n",
    "    print(\"Unidades y dominios esperados:\")\n",
    "    if \"liq_um\" in df.columns:\n",
    "        print(\" - liq_um: volumen en hectolitros (HL), valores válidos >= 0\")\n",
    "        print(\"   Valores negativos:\", (df[\"liq_um\"] < 0).sum())\n",
    "        print(\"   Máximo:\", df[\"liq_um\"].max(), \"mínimo:\", df[\"liq_um\"].min())\n",
    "\n",
    "    print(\"Reglas de negocio y consistencia de llaves:\")\n",
    "    if set([\"id_cliente\", \"id_periodo\", \"id_sku_venta\"]).issubset(df.columns):\n",
    "        dups = df.duplicated(subset=[\"id_cliente\", \"id_periodo\", \"id_sku_venta\"]).sum()\n",
    "        print(f\"Duplicados por (id_cliente, id_periodo, id_sku_venta): {dups}\")\n",
    "    else:\n",
    "        print(\"Sin llaves obvias detectadas.\")\n",
    "\n",
    "    print(\"Valores faltantes:\")\n",
    "    top_nulos = df.isna().mean().sort_values(ascending=False).head(10)\n",
    "    print(top_nulos)\n",
    "\n",
    "    # ===== NUEVO: guardado a Excel (si se provee) =====\n",
    "    if writer is not None and dataset_name is not None:\n",
    "        # esquema básico: dtype, únicos, % nulos\n",
    "        schema_rows = []\n",
    "        for col in df.columns:\n",
    "            schema_rows.append({\n",
    "                \"col\": col,\n",
    "                \"dtype\": str(df[col].dtype),\n",
    "                \"nunique\": df[col].nunique(dropna=True),\n",
    "                \"null_pct\": round(df[col].isna().mean() * 100, 2)\n",
    "            })\n",
    "        schema_df = pd.DataFrame(schema_rows).sort_values(\"col\")\n",
    "        schema_df.to_excel(writer, sheet_name=f\"{dataset_name[:25]}_schema\", index=False)\n",
    "\n",
    "        top_nulos.rename(\"null_pct\").to_frame().to_excel(\n",
    "            writer, sheet_name=f\"{dataset_name[:25]}_nulos\"\n",
    "        )\n",
    "\n",
    "print('*** Revisión general dataset de clientes ***')\n",
    "revision_gral_dataset(clientes, dataset_name=\"clientes\", writer=writer)\n",
    "print('*** Revisión general dataset de barrios ***')\n",
    "revision_gral_dataset(barrios, dataset_name=\"barrios\", writer=writer)\n",
    "print('*** Revisión general dataset variables macroeconómicas ***')\n",
    "revision_gral_dataset(macro_vars, dataset_name=\"macro_vars\", writer=writer)\n",
    "print('*** Revisión general dataset de ventas cervezas ***')\n",
    "revision_gral_dataset(ventas_cervezas, dataset_name=\"ventas_cervezas\", writer=writer)\n",
    "print('*** Revisión general dataset de ventas analcohólicos ***')\n",
    "revision_gral_dataset(ventas_analcoholicos, dataset_name=\"ventas_analcoholicos\", writer=writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis univariado\n",
    "def analisis_univariado(dfx, dataset_name=None, save_png=False, bins=30, max_vars=50, writer=None, save_outlier_rows=False):\n",
    "    df = dfx.copy()\n",
    "    print(\"Estadísticos descriptivos principales:\")\n",
    "    desc = df.describe(percentiles=[0.25, 0.5, 0.75]).T\n",
    "    desc[\"skew\"] = df.skew(numeric_only=True)\n",
    "    desc[\"kurtosis\"] = df.kurtosis(numeric_only=True)\n",
    "    print(desc)\n",
    "\n",
    "    # ===== Guardar descriptivo a Excel (si se provee) =====\n",
    "    if writer is not None and dataset_name is not None:\n",
    "        desc.to_excel(writer, sheet_name=f\"{dataset_name[:28]}_desc\")\n",
    "\n",
    "    # Detección de colas pesadas y outliers (método IQR)\n",
    "    num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "    out_summary_rows = []\n",
    "    out_rows_long = []   # opcional (muestra filas outlier)\n",
    "\n",
    "    for col in num_cols:\n",
    "        s = df[col].dropna()\n",
    "        n = len(s)\n",
    "        if n == 0:\n",
    "            continue\n",
    "\n",
    "        Q1, Q3 = np.percentile(s, [25, 75])\n",
    "        IQR = Q3 - Q1\n",
    "        lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "        mask = (s < lower) | (s > upper)\n",
    "        n_out = int(mask.sum())\n",
    "        pct_out = (n_out / n) * 100 if n > 0 else 0.0\n",
    "\n",
    "        out_summary_rows.append({\n",
    "            \"col\": col,\n",
    "            \"count\": n,\n",
    "            \"outliers\": n_out,\n",
    "            \"pct_outliers\": round(pct_out, 2),\n",
    "            \"Q1\": Q1,\n",
    "            \"Q3\": Q3,\n",
    "            \"IQR\": IQR,\n",
    "            \"lower\": lower,\n",
    "            \"upper\": upper,\n",
    "            \"min\": float(s.min()),\n",
    "            \"max\": float(s.max()),\n",
    "        })\n",
    "\n",
    "        print(f\"{col}: outliers {n_out} ({pct_out:.2f}%)  |  IQR=[{Q1:.3f},{Q3:.3f}]  thr=[{lower:.3f},{upper:.3f}]\")\n",
    "\n",
    "        if save_outlier_rows and n_out > 0:\n",
    "            # guardamos una muestra acotada de filas outlier (hasta 200 total por dataset)\n",
    "            s_out = s[mask]\n",
    "            # tomamos una muestra por columna (máx 200/num_cols para no reventar)\n",
    "            k = max(1, 200 // max(1, len(num_cols)))\n",
    "            s_out_sample = s_out.head(k)\n",
    "            out_rows_long.append(\n",
    "                pd.DataFrame({\n",
    "                    \"col\": col,\n",
    "                    \"index\": s_out_sample.index,\n",
    "                    \"value\": s_out_sample.values\n",
    "                })\n",
    "            )\n",
    "\n",
    "    # ===== Guardar resumen de outliers (y sample de filas) a Excel =====\n",
    "    if writer is not None and dataset_name is not None and len(out_summary_rows) > 0:\n",
    "        out_summary_df = pd.DataFrame(out_summary_rows).sort_values(\"pct_outliers\", ascending=False)\n",
    "        out_summary_df.to_excel(writer, sheet_name=f\"{dataset_name[:25]}_outliers\", index=False)\n",
    "\n",
    "        if save_outlier_rows and len(out_rows_long) > 0:\n",
    "            out_rows_df = pd.concat(out_rows_long, ignore_index=True)\n",
    "            # Por si el index original es jerárquico o no numérico, lo convertimos a str\n",
    "            out_rows_df[\"index\"] = out_rows_df[\"index\"].astype(str)\n",
    "            out_rows_df.to_excel(writer, sheet_name=f\"{dataset_name[:23]}_out_rows\", index=False)\n",
    "\n",
    "    if len(num_cols) > max_vars:\n",
    "        num_cols = num_cols[:max_vars]  # por si hay demasiadas columnas\n",
    "\n",
    "    out_dir = None\n",
    "    if save_png and dataset_name is not None:\n",
    "        out_dir = PLOTS_DIR / dataset_name\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for col in num_cols:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(df[col], kde=True, bins=bins)\n",
    "        plt.title(f\"Distribución y densidad - {col}\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.boxplot(x=df[col])\n",
    "        plt.title(f\"Boxplot - {col}\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if out_dir is not None:\n",
    "            safe_col = str(col).replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "            plt.savefig(out_dir / f\"{dataset_name}__{safe_col}.png\", dpi=150)\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "analisis_univariado(clientes, dataset_name=\"clientes\", save_png=True, writer=writer, save_outlier_rows=True)\n",
    "analisis_univariado(barrios, dataset_name=\"barrios\", save_png=True, writer=writer, save_outlier_rows=True)\n",
    "analisis_univariado(macro_vars, dataset_name=\"macro_vars\", save_png=True, writer=writer, save_outlier_rows=True)\n",
    "analisis_univariado(ventas_cervezas, dataset_name=\"ventas_cervezas\", save_png=True, writer=writer, save_outlier_rows=True)\n",
    "analisis_univariado(ventas_analcoholicos, dataset_name=\"ventas_analcoholicos\", save_png=True, writer=writer, save_outlier_rows=True)\n",
    "\n",
    "writer.close()\n",
    "print(f\"Excel con descriptivos + outliers: {excel_path}\")\n",
    "print(f\"PNGs: {PLOTS_DIR} (subcarpetas por dataset)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profile_report(df, dataset_name):\n",
    "    profile = ProfileReport(df, title=f\"EDA {dataset_name}\", explorative=True)\n",
    "    profile.to_file(f\"./data/output/eda_{dataset_name}.html\")\n",
    "\n",
    "get_profile_report(clientes, \"clientes\")\n",
    "get_profile_report(barrios, \"barrios\")\n",
    "get_profile_report(macro_vars, \"macro_vars\")\n",
    "get_profile_report(ventas_cervezas, \"ventas_cervezas\")\n",
    "get_profile_report(ventas_analcoholicos, \"ventas_analcoholicos\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM0McJe3kJIcjBWfFelJeT0",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
